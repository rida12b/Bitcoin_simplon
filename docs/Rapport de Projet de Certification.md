# Rapport de Projet de Certification

**Titre du Projet :**Â Bitcoin Analyzer  
**Candidat :**Â Rida Boualam 
**Certification VisÃ©e :**Â RNCP37827 - DÃ©veloppeur en Intelligence Artificielle  
**Date :**Â Juillet 2025

---

## Sommaire

1. **Introduction et Analyse du Besoin (C14)**

2. **Conception et Architecture Technique (C15)**

3. **Ã‰preuve E1 : La ChaÃ®ne de la DonnÃ©e (Bloc 1, C1-C5)**

4. **Ã‰preuves E2 & E3 : IntÃ©gration du Service d'IA (Bloc 2, C6-C13)**

5. **Ã‰preuves E4 & E5 : L'Application ComplÃ¨te (Bloc 3, C14-C21)**

6. **Conclusion**

---

## 1. Introduction et Analyse du Besoin (CompÃ©tence C14)

### a. Contexte et Vision du Projet

Le marchÃ© des cryptomonnaies, et en particulier du Bitcoin, est caractÃ©risÃ© par une forte volatilitÃ© et un flux d'informations constant et dispersÃ©. Pour un investisseur non-expert, il est difficile de se forger une opinion Ã©clairÃ©e sans passer des heures Ã  agrÃ©ger et analyser des donnÃ©es de sources multiples.

**Vision :**Â "Bitcoin Analyzer" a pour but de devenir le tableau de bord de rÃ©fÃ©rence pour les investisseurs amateurs, en centralisant les donnÃ©es de marchÃ©, les actualitÃ©s pertinentes et en fournissant une analyse de tendance simplifiÃ©e grÃ¢ce Ã  l'Intelligence Artificielle. L'objectif est de rendre l'information financiÃ¨re sur le BitcoinÂ **accessible, digeste et actionnable**.

### b. Persona Utilisateur Cible

Pour guider la conception, nous dÃ©finissons un persona utilisateur principal.

#### **ğŸ‘¤ Alex, 30 ans - L'Investisseur Prudent**

- **Biographie :**Â Alex travaille dans le marketing et s'intÃ©resse aux nouvelles technologies. Il a investi une petite partie de ses Ã©conomies dans le Bitcoin mais n'a ni le temps ni l'expertise pour suivre les analyses financiÃ¨res complexes.

- **Besoins et Objectifs :**
  
  - Comprendre rapidement la "tempÃ©rature" du marchÃ© chaque jour.
  
  - AccÃ©der aux nouvelles importantes qui pourraient influencer le cours.
  
  - Visualiser la tendance rÃ©cente sans avoir Ã  lire des graphiques complexes.

- **Frustrations actuelles :**
  
  - "Je suis noyÃ© sous le jargon technique sur Twitter et les sites spÃ©cialisÃ©s."
  
  - "Je ne sais pas si une news est rÃ©ellement importante ou si c'est juste du bruit."
  
  - "Les graphiques de trading sont trop intimidants pour moi."

### c. RÃ©cits Utilisateurs (User Stories)

Les fonctionnalitÃ©s de l'application sont dÃ©finies par les besoins de notre persona, Alex.

---

#### **ID : US-01 - Consultation des ActualitÃ©s CentralisÃ©es**

- **En tant que**Â Alex, l'investisseur prudent,

- **Je veux**Â consulter les titres des derniÃ¨res actualitÃ©s sur une seule et mÃªme page,

- **Afin de**Â me tenir informÃ© rapidement des Ã©vÃ©nements majeurs sans avoir Ã  visiter plusieurs sites.

**CritÃ¨res d'Acceptation :**

- Le tableau de bord doit afficher les 5 derniÃ¨res actualitÃ©s.

- Chaque actualitÃ© doit afficher son titre complet.

- Le titre de chaque actualitÃ© doit Ãªtre un lien cliquable qui redirige vers l'article original dans un nouvel onglet.

- Si aucune actualitÃ© n'est disponible, un message clair ("Aucune actualitÃ© Ã  afficher.") doit apparaÃ®tre.

---

#### **ID : US-02 - AccÃ¨s Ã  une Analyse SimplifiÃ©e par l'IA**

- **En tant que**Â Alex,

- **Je veux**Â lire une analyse de la tendance du marchÃ© rÃ©digÃ©e en langage simple et concis,

- **Afin de**Â comprendre l'orientation gÃ©nÃ©rale du marchÃ© (haussiÃ¨re, baissiÃ¨re, stable) sans nÃ©cessiter de connaissances en analyse technique.

**CritÃ¨res d'Acceptation :**

- L'analyse doit Ãªtre gÃ©nÃ©rÃ©e par le service d'Intelligence Artificielle.

- Le texte de l'analyse ne doit pas dÃ©passer 3 phrases pour rester concis.

- L'analyse doit Ãªtre prÃ©sentÃ©e dans une section clairement identifiÃ©e ("Analyse de l'IA").

- **AccessibilitÃ© :**Â Le fond de la section d'analyse doit avoir un contraste de couleur suffisant avec le texte pour Ãªtre lisible (respect des normes WCAG AA).

- En cas d'Ã©chec de la gÃ©nÃ©ration de l'analyse, la section ne doit pas s'afficher ou doit afficher un message d'erreur discret.

---

#### **ID : US-03 - Visualisation de l'Historique RÃ©cent des Prix**

- **En tant que**Â Alex,

- **Je veux**Â voir un historique simple des prix de clÃ´ture des derniÃ¨res 24 heures,

- **Afin de**Â visualiser la volatilitÃ© rÃ©cente du Bitcoin de maniÃ¨re factuelle.

**CritÃ¨res d'Acceptation :**

- Le tableau de bord doit afficher une liste ou un tableau des prix de clÃ´ture.

- Chaque entrÃ©e doit indiquer le timestamp (ou l'heure) et le prix.

- La liste doit Ãªtre triÃ©e de la plus rÃ©cente Ã  la plus ancienne.

- Par dÃ©faut, les 24 derniers points de donnÃ©es horaires sont affichÃ©s.

### d. FonctionnalitÃ©s Hors PÃ©rimÃ¨tre (Version 1.0)

Pour assurer une livraison rapide et ciblÃ©e, les fonctionnalitÃ©s suivantes ne sont pas incluses dans la version initiale :

- CrÃ©ation de comptes utilisateurs et authentification.

- Personnalisation du tableau de bord.

- Graphiques interactifs avancÃ©s.

- SystÃ¨me d'alertes par email ou notification.

## 2. Conception et Architecture Technique (CompÃ©tence C15)

### a. SchÃ©ma d'Architecture DÃ©taillÃ©

![Untitled diagram _ Mermaid Chart-2025-07-09-121014.png](C:\Users\Ridab\Downloads\Untitled%20diagram%20_%20Mermaid%20Chart-2025-07-09-121014.png)

**Description des flux :**

1. L'utilisateur accÃ¨de au tableau de bord via son navigateur, envoyant une requÃªte au serveurÂ **Django**Â sur le port 8000.

2. La vue Django agit comme un client et envoie des requÃªtes HTTP Ã  l'APIÂ **FastAPI**Â sur le port 8001 pour obtenir les donnÃ©es (news, prix, analyse).

3. L'API FastAPI orchestre la rÃ©cupÃ©ration des donnÃ©es :  
   a. Elle interroge la base de donnÃ©esÂ **SQLite**Â pour les donnÃ©es de marchÃ© et les actualitÃ©s.  
   b. Elle appelle l'API externe deÂ **Google Gemini**Â pour gÃ©nÃ©rer l'analyse de tendance.

4. FastAPI agrÃ¨ge les rÃ©ponses et les retourne au formatÂ **JSON**Â Ã  Django.

5. Django utilise ces donnÃ©es pour populer le template HTML et renvoie la page web complÃ¨te au navigateur de l'utilisateur.

### b. Pile Technologique et Justification des Choix

Chaque technologie a Ã©tÃ© sÃ©lectionnÃ©e aprÃ¨s une analyse de ses forces et de sa pertinence pour le projet, en considÃ©rant Ã©galement des alternatives.

#### Langage : Python 3.11

- **Justification :**Â Choix naturel pour un projet d'IA grÃ¢ce Ã  son Ã©cosystÃ¨me mature (Pandas, Scikit-learn pour des Ã©volutions futures) et ses excellentes bibliothÃ¨ques pour le dÃ©veloppement web (fastapi,Â django) et l'accÃ¨s aux donnÃ©es (requests,Â beautifulsoup4). Sa syntaxe claire favorise un dÃ©veloppement rapide et une maintenance aisÃ©e.

#### Backend : FastAPI

- **Justification :**
  
  - **Haute Performance :**Â BasÃ© sur Starlette et Pydantic, FastAPI est l'un des frameworks Python les plus rapides, idÃ©al pour une API qui se doit d'Ãªtre rÃ©active.
  
  - **Documentation Automatique (validation de C5) :**Â GÃ©nÃ¨re nativement une documentation interactive (Swagger UI / OpenAPI), ce qui est un gain de temps majeur et une exigence de qualitÃ© professionnelle pour toute API.
  
  - **Validation des DonnÃ©es :**Â Utilise Pydantic pour une validation robuste et claire des types de donnÃ©es en entrÃ©e et en sortie, rÃ©duisant ainsi les bugs.

- **Alternative Ã‰cartÃ©e :**
  
  - **Flask :**Â Bien que plus lÃ©ger, Flask ne propose pas de validation de donnÃ©es ni de documentation automatique nativement. Les ajouter nÃ©cessiterait des bibliothÃ¨ques tierces (ex: Flask-RESTful, Flasgger), complexifiant la maintenance et ajoutant des points de dÃ©faillance potentiels.
  
  - **Django REST Framework (DRF) :**Â TrÃ¨s puissant mais plus lourd et plus complexe Ã  configurer pour une API simple comme celle-ci. L'approche "tout-en-un" de DRF Ã©tait superflue, FastAPI offrant un meilleur Ã©quilibre performance/simplicitÃ© pour ce projet.

#### Frontend : Django

- **Justification :**
  
  - **Framework Complet ("Batteries included") :**Â Offre une structure robuste pour construire une application web complÃ¨te avec un ORM, un systÃ¨me de templates puissant, et des fonctionnalitÃ©s de sÃ©curitÃ© intÃ©grÃ©es.
  
  - **DÃ©monstration de CompÃ©tence :**Â Utiliser Django comme simple consommateur d'API dÃ©montre la maÃ®trise des architectures dÃ©couplÃ©es, une compÃ©tence trÃ¨s recherchÃ©e dans le monde professionnel, qui valorise la sÃ©paration des responsabilitÃ©s.

- **Alternative Ã‰cartÃ©e :**
  
  - **Streamlit/Gradio :**Â Ces outils sont excellents pour des prototypes rapides de data science et des interfaces de dÃ©monstration de modÃ¨les. Cependant, ils offrent moins de contrÃ´le sur le design (HTML/CSS) et la structure de l'application, les rendant moins adaptÃ©s pour construire une application web personnalisable et Ã©volutive destinÃ©e Ã  un utilisateur final.

#### Base de DonnÃ©es : SQLite

- **Justification :**
  
  - **SimplicitÃ© :**Â Aucune installation de serveur requise, la base de donnÃ©es est un simple fichier. C'est la solution parfaite pour le dÃ©veloppement, les tests automatisÃ©s et un dÃ©ploiement lÃ©ger.
  
  - **IntÃ©gration Python :**Â Fait partie de la bibliothÃ¨que standard de Python, ne nÃ©cessitant aucune dÃ©pendance externe pour fonctionner.

- **Vision d'Ã‰volution (ScalabilitÃ©) :**Â SQLite est suffisant pour la version 1 du projet. Pour une mise en production Ã  plus grande Ã©chelle, l'architecture est pensÃ©e pour une migration future. Le code d'accÃ¨s aux donnÃ©es Ã©tant bien isolÃ©, il serait aisÃ© de le remplacer par des appels Ã  un SGBD plus robuste commeÂ **PostgreSQL**. Cette anticipation dÃ©montre une rÃ©flexion sur le cycle de vie complet de l'application.

#### Service d'IA : Google Gemini Pro

- **Justification :**Â Le choix de ce modÃ¨le n'est pas arbitraire. Il est le rÃ©sultat d'un benchmark formel documentÃ© dansÂ docs/benchmark_ia.md. Gemini Pro a Ã©tÃ© sÃ©lectionnÃ© car il offre le meilleur compromis entre :
  
  1. **Performance :**Â Un score Elo trÃ¨s compÃ©titif sur la LMSys Chatbot Arena.
  
  2. **CoÃ»t :**Â Un tarif trÃ¨s abordable, rendant le projet Ã©conomiquement viable.
  
  3. **FacilitÃ© d'intÃ©gration :**Â Une bibliothÃ¨que Python officielle (google-generativeai) claire et bien documentÃ©e.

## 3. Ã‰preuve E1 : La ChaÃ®ne de la DonnÃ©e (Bloc 1, C1-C5)

Pour alimenter l'application, j'ai mis en place une chaÃ®ne de traitement de la donnÃ©e complÃ¨te, fiable et automatisÃ©e. Cette chaÃ®ne couvre la collecte depuis des sources hÃ©tÃ©rogÃ¨nes, le nettoyage, le stockage et la mise Ã  disposition via une API REST, validant ainsi l'ensemble des compÃ©tences du Bloc 1.

### 3.1 Automatisation de l'Extraction Multi-sources (C1, C3)

La premiÃ¨re Ã©tape a consistÃ© Ã  automatiser la collecte de donnÃ©es de natures diffÃ©rentes pour garantir une vision complÃ¨te du marchÃ©.

#### Source 1 : API REST Externe (Coinalyze) - CompÃ©tence C1

Pour obtenir les donnÃ©es de marchÃ© financiÃ¨res (prix, volume), j'ai dÃ©veloppÃ© le scriptÂ scripts/extraction_api.py. Il interroge l'API de Coinalyze de maniÃ¨re robuste et sÃ©curisÃ©e. La sÃ©curitÃ© des informations d'authentification a Ã©tÃ© une prioritÃ© : la clÃ© API est stockÃ©e dans un fichierÂ .envÂ (exclu du contrÃ´le de version viaÂ .gitignore) et chargÃ©e dynamiquement en mÃ©moire grÃ¢ce Ã  la bibliothÃ¨queÂ python-dotenv.



```
// Extrait de scripts/extraction_api.py
```

![Capture dâ€™Ã©cran 2025-07-09 150407.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20150407.png)

#### Source 2 : Scraping Web (Bitcoin Magazine) - CompÃ©tence C1

Pour les actualitÃ©s, qui n'Ã©taient pas disponibles via une API simple, j'ai dÃ©veloppÃ© le scriptÂ scripts/extraction_news.py. Il utilise les bibliothÃ¨quesÂ requestsÂ pour tÃ©lÃ©charger le contenu HTML de la page d'actualitÃ©s etÂ BeautifulSoupÂ pour le parser. UnÂ User-AgentÂ spÃ©cifique est dÃ©fini dans les en-tÃªtes pour simuler un navigateur lÃ©gitime et Ã©viter les blocages de sÃ©curitÃ© courants. Ce processus transforme efficacement des donnÃ©es non structurÃ©es (HTML) en donnÃ©es structurÃ©es (une liste d'articles avec titre et lien).



// Extrait de scripts/extraction_news.py - CompÃ©tence C1



![](C:\Users\Ridab\AppData\Roaming\marktext\images\2025-07-09-15-44-22-image.png)

![](C:\Users\Ridab\AppData\Roaming\marktext\images\2025-07-09-15-44-52-image.png)





#### AgrÃ©gation et Nettoyage - CompÃ©tence C3

Une fois les donnÃ©es brutes extraites, elles sont immÃ©diatement nettoyÃ©es et formatÃ©es pour garantir leur qualitÃ© et leur homogÃ©nÃ©itÃ© avant le stockage. Par exemple, dansÂ extraction_api.py, les donnÃ©es JSON de l'API sont transformÃ©es en une liste de dictionnaires Python avec des clÃ©s normalisÃ©es (timestamp,Â open,Â high,Â low,Â close,Â volume), prÃ©parant ainsi le jeu de donnÃ©es final.

### 3.2 Extraction via RequÃªtes SQL (C2)

Pour dÃ©montrer la capacitÃ© Ã  interagir avec des systÃ¨mes d'information existants (un cas trÃ¨s courant en entreprise), j'ai simulÃ© une base de donnÃ©es "legacy" et dÃ©veloppÃ© un script pour en extraire les donnÃ©es via des requÃªtes SQL standard.

D'abord, le scriptÂ scripts/setup_source_db.pyÂ crÃ©e une base de donnÃ©esÂ source_data.dbÂ contenant une tableÂ legacy_articles.  
Ensuite, le scriptÂ scripts/extraction_sql.pyÂ se connecte Ã  cette base source et exÃ©cute une requÃªte SQLÂ SELECTÂ pour rÃ©cupÃ©rer les articles.

```
// Extrait de scripts/extraction_sql.py - CompÃ©tence C2
```

![Capture dâ€™Ã©cran 2025-07-09 150143.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20150143.png)

Les donnÃ©es sont ensuite traitÃ©es et insÃ©rÃ©es dans la base principale

Cette approche valide la maÃ®trise de l'extraction de donnÃ©es depuis un SGBD via le langage SQL.

### 3.3 Stockage et ModÃ©lisation des DonnÃ©es (C4)

Toutes les donnÃ©es collectÃ©es et nettoyÃ©es sont centralisÃ©es dans une base de donnÃ©es SQLite unique,Â data/bitcoin.db. Le moduleÂ scripts/stockage.pyÂ est responsable de la crÃ©ation de la base et de la dÃ©finition du schÃ©ma des tables.

Pour garantir l'intÃ©gritÃ© des donnÃ©es et l'idempotence des scripts de collecte (c'est-Ã -dire qu'on peut les lancer plusieurs fois sans crÃ©er de doublons), des contraintesÂ UNIQUEÂ ont Ã©tÃ© placÃ©es sur les champs clÃ©s.

```
// SchÃ©ma SQL dÃ©fini dans scripts/stockage.py - CompÃ©tence C4
-- CrÃ©ation de la table pour les prix du Bitcoin
```

![Capture dâ€™Ã©cran 2025-07-09 150013.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20150013.png)

Cette modÃ©lisation rigoureuse assure la fiabilitÃ© et la cohÃ©rence du jeu de donnÃ©es qui alimentera l'application.

### 3.4 Exposition des DonnÃ©es via une API REST (C5)

La derniÃ¨re Ã©tape du Bloc 1 consiste Ã  rendre les donnÃ©es stockÃ©es accessibles de maniÃ¨re programmatique. J'ai dÃ©veloppÃ© pour cela une API en utilisant le framework FastAPI, choisi pour sa performance et sa capacitÃ© Ã  gÃ©nÃ©rer automatiquement une documentation conforme au standard OpenAPI.

L'API, dÃ©finie dansÂ api/app.py, expose plusieurs endpoints, dont :

- /latest-newsÂ : pour rÃ©cupÃ©rer les derniÃ¨res actualitÃ©s.

- /price-historyÂ : pour obtenir l'historique des prix.

L'un des livrables les plus importants de cette compÃ©tence est la documentation interactive (Swagger UI) gÃ©nÃ©rÃ©e automatiquement par FastAPI. Elle permet Ã  n'importe quel dÃ©veloppeur (ou au jury) de comprendre et de tester l'API sans avoir Ã  lire une ligne de code, ce qui est une pratique professionnelle essentielle.

> **Figure 1 : Documentation interactive de l'API (Swagger UI) gÃ©nÃ©rÃ©e automatiquement par FastAPI.** On peut y voir les endpoints disponibles (`/latest-price`, `/price-history`), leurs paramÃ¨tres, ainsi que la possibilitÃ© de les tester en direct, validant la compÃ©tence C5.
> 
> ![Capture dâ€™Ã©cran 2025-07-09 142143.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20142143.png)

![Capture dâ€™Ã©cran 2025-07-09 142231.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20142231.png)

![Capture dâ€™Ã©cran 2025-07-09 142253.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20142253.png)

## 4. Ã‰preuves E2 & E3 : IntÃ©gration du Service d'IA (Bloc 2, C6-C13)

Une fois la chaÃ®ne de donnÃ©es Ã©tablie, le cÅ“ur du projet a Ã©tÃ© d'enrichir ces donnÃ©es grÃ¢ce Ã  un service d'intelligence artificielle. Ce bloc dÃ©montre une approche professionnelle complÃ¨te : de la veille technologique Ã  la sÃ©lection du modÃ¨le, son intÃ©gration, son exposition via une API, et enfin, la mise en place de tests et d'une chaÃ®ne de livraison continue pour garantir sa fiabilitÃ©.

### 4.1 Veille, Benchmark et SÃ©lection du Service (E2 : C6, C7, C8)

Le choix d'un service d'IA ne doit pas Ãªtre arbitraire. Il doit rÃ©sulter d'une analyse rigoureuse de l'Ã©tat de l'art et des contraintes du projet.

#### 4.1.1 Veille Technologique Active (C6)

Pour garantir que le projet utilise des technologies pertinentes et des pratiques Ã  jour, une veille technologique active a Ã©tÃ© menÃ©e. PlutÃ´t qu'une simple lecture passive, la mÃ©thodologie s'est concentrÃ©e sur des sources primaires et des discussions techniques :

- **Suivi de DÃ©pÃ´ts GitHub ClÃ©s :**Â Surveillance active desÂ issues,Â discussionsÂ etÂ releasesÂ de projets commeÂ google/generative-ai-pythonÂ etÂ tiangolo/fastapi.

- **Consultation de Listes "Awesome" :**Â Suivi rÃ©gulier de listes communautaires commeÂ awesome-generative-aiÂ pour dÃ©couvrir de nouveaux outils.

- **Analyse de Plateformes Techniques :**Â Participation aux discussions sur Twitter et Reddit (r/Cursor).

Cette veille, documentÃ©e dansÂ docs/veille_technologique.md, a permis d'identifier des opportunitÃ©s concrÃ¨tes. Par exemple, la dÃ©couverte de la bibliothÃ¨queÂ litellmÂ a Ã©tÃ© notÃ©e comme une piste d'Ã©volution intÃ©ressante pour une future V2 du projet afin de supporter plusieurs modÃ¨les d'IA de maniÃ¨re unifiÃ©e.

#### 4.1.2 Benchmark et SÃ©lection du ModÃ¨le d'IA (C7)

Le choix du modÃ¨le de langage (LLM) est une dÃ©cision technique critique qui impacte directement la performance, le coÃ»t et la viabilitÃ© du projet. Pour garantir une dÃ©cision objective et professionnelle, j'ai rÃ©alisÃ© un benchmark formel, dÃ©taillÃ© dans le documentÂ docs/benchmark_ia.md.

**MÃ©thodologie de Benchmark :**  
La sÃ©lection s'est basÃ©e sur les donnÃ©es du leaderboardÂ **Artificial Analysis AI**, une source spÃ©cialisÃ©e dans l'Ã©valuation des fournisseurs d'API pour les dÃ©veloppeurs. Cette source a Ã©tÃ© privilÃ©giÃ©e pour son focus sur des mÃ©triques concrÃ¨tes et directement applicables Ã  notre projet :

1. **QualitÃ© d'Analyse  :**Â BasÃ©e sur l'**"Artificial Analysis Intelligence Index"**, un score propriÃ©taire qui Ã©value la capacitÃ© de raisonnement du modÃ¨le. C'est le critÃ¨re le plus important.

2. **CoÃ»t de l'API  :**Â BasÃ© sur leÂ **"Blended USD/1M Tokens"**, un prix mixte qui reflÃ¨te un usage rÃ©aliste. Crucial pour la viabilitÃ© Ã©conomique.

3. **Vitesse de RÃ©ponse  :**Â MesurÃ©e par leÂ **"Total Response (s)"**Â en secondes. Un facteur important pour l'expÃ©rience utilisateur, bien que non-critique pour notre cas d'usage asynchrone.

**Alternatives Ã‰tudiÃ©es :**  
J'ai comparÃ© plusieurs des modÃ¨les les plus performants et pertinents du marchÃ© :

- **Google Gemini 2.5 Pro (AI Studio)**Â : Le candidat principal.

- **OpenAI o3 (via OpenAI et Azure)**Â : Le concurrent direct en termes de qualitÃ©.

- **OpenAI o4-mini (via OpenAI et Azure)**Â : Un challenger trÃ¨s compÃ©titif sur le plan du coÃ»t.

- **DeepSeek R1 0528**Â : Une alternative open-source trÃ¨s performante et Ã©conomique.

**Tableau Comparatif SynthÃ©tique (basÃ© sur Artificial Analysis AI) :**

![](C:\Users\Ridab\AppData\Roaming\marktext\images\2025-07-09-14-42-34-image.png)



**DÃ©cision Finale et Justification Technique :**

Le choix s'est portÃ© surÂ **Google Gemini 2.5 Pro**. Cette dÃ©cision est justifiÃ©e par une combinaison de performance de pointe et de flexibilitÃ© stratÃ©gique :

- **Performance de Pointe (CritÃ¨re nÂ°1) :**Â Gemini 2.5 Pro atteint le score d'intelligence maximal deÂ **70**Â sur le benchmarkÂ Artificial Analysis, le plaÃ§ant au sommet du marchÃ© en termes de capacitÃ© de raisonnement. C'Ã©tait le critÃ¨re non nÃ©gociable pour garantir la qualitÃ© des analyses fournies Ã  l'utilisateur.

- **Avantage StratÃ©gique - FenÃªtre de Contexte :**Â Avec une fenÃªtre de contexte deÂ **1 million de tokens**, ce modÃ¨le offre des perspectives d'Ã©volution majeures pour l'analyse de documents financiers longs ou de multiples sources d'actualitÃ©s, une capacitÃ© que peu de concurrents Ã©galent.

- **FlexibilitÃ© Architecturale et Ã‰conomique :**Â L'Ã©cosystÃ¨me Gemini permet de basculer de maniÃ¨re transparente vers un modÃ¨le plus rapide et Ã©conomique commeÂ **Gemini 2.5 Flash**Â via une simple modification du nom du modÃ¨le dans l'appel API. Cette agilitÃ© permet d'optimiser les coÃ»ts ou la latence Ã  l'avenirÂ **sans aucune refonte de l'architecture**, ce qui reprÃ©sente un atout majeur en termes de maintenabilitÃ© et de coÃ»t Ã  long terme.

En somme, Gemini 2.5 Pro a Ã©tÃ© choisi non seulement pour sa performance brute actuelle, mais aussi pour saÂ **flexibilitÃ© et son potentiel d'Ã©volution**, garantissant la pÃ©rennitÃ© et l'agilitÃ© technique du projet.

#### 4.1.3 ParamÃ©trage du Service (C8)

L'intÃ©gration du service Gemini Pro a Ã©tÃ© rÃ©alisÃ©e via la bibliothÃ¨que Python officielleÂ google-generativeai. ConformÃ©ment aux bonnes pratiques de sÃ©curitÃ©, la clÃ© d'API a Ã©tÃ© configurÃ©e via une variable d'environnement, chargÃ©e parÂ python-dotenv, garantissant qu'aucune information sensible n'est exposÃ©e dans le code source.

### 4.2 Exposition et IntÃ©gration du ModÃ¨le (E3 : C9, C10)

#### 4.2.1 Exposition du ModÃ¨le via l'API (C9)

La valeur ajoutÃ©e de l'IA est exposÃ©e via l'endpointÂ /price-analysisÂ de l'API FastAPI. Cet endpoint ne se contente pas de relayer une requÃªte ; il met en Å“uvre une stratÃ©gie deÂ prompt engineeringÂ pour maximiser la pertinence de la rÃ©ponse du LLM.

Le processus est le suivant :

1. RÃ©cupÃ©rer l'historique rÃ©cent des prix depuis la base de donnÃ©es SQLite.

2. Formatter ces donnÃ©es numÃ©riques en un texte descriptif et comprÃ©hensible.

3. Construire un prompt dÃ©taillÃ© qui assigne un rÃ´le au modÃ¨le ("Tu es un analyste financier pour un dÃ©butant"), fournit le contexte (les donnÃ©es de prix) et spÃ©cifie le format de la rÃ©ponse attendue (concise et en langage simple).

4. Appeler le module d'analyse IA avec ce prompt.

5. Retourner la rÃ©ponse textuelle du modÃ¨le dans un format JSON propre.

```
// Extrait de api/app.py - CompÃ©tence C9
```

![Capture dâ€™Ã©cran 2025-07-09 145722.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20145722.png)

#### 4.2.2 IntÃ©gration dans l'Application Frontend (C10)

Cette fonctionnalitÃ© d'IA est ensuite rendue accessible Ã  l'utilisateur final. L'application Django, agissant comme un client, envoie une requÃªte HTTP Ã  l'endpointÂ /price-analysisÂ de l'API FastAPI pour rÃ©cupÃ©rer l'analyse et l'afficher sur le tableau de bord. Cette communication inter-services est une dÃ©monstration clÃ© de l'architecture dÃ©couplÃ©e du projet.

### 4.3 Monitoring, Tests et CI/CD du Service IA (E3 : C11, C12, C13)

Pour assurer la qualitÃ© et la robustesse du service d'IA, une approche MLOps a Ã©tÃ© adoptÃ©e, intÃ©grant le monitoring, les tests automatisÃ©s et la livraison continue.

#### 4.3.1 Monitoring du ModÃ¨le (C11)

Le moduleÂ loggingÂ de Python a Ã©tÃ© intÃ©grÃ© dans l'API FastAPI pour tracer de maniÃ¨re exhaustive toutes les interactions avec le service d'IA. Chaque appel Ã  l'endpointÂ /price-analysisÂ gÃ©nÃ¨re des logs qui permettent de suivre :

- La rÃ©ception de la requÃªte.

- Le dÃ©but de l'appel Ã  l'API externe de Gemini.

- La rÃ©ception rÃ©ussie de la rÃ©ponse.

- Toute erreur survenant durant le processus.

**Preuve de logging (Extrait deÂ docs/exemples_de_logs.txt) :**

```
2025-07-09 10:23:39,098 - INFO - API - RequÃªte reÃ§ue pour l'analyse de prix (limite=24).2025-07-09 10:23:39,103 - INFO - API - Appel au service d'analyse IA (Gemini)...
2025-07-09 10:23:46,068 - INFO - API - Analyse IA reÃ§ue avec succÃ¨s.
INFO:     127.0.0.1:61446 - "GET /price-analysis HTTP/1.1" 200 OK
```

Ce monitoring est essentiel pour le diagnostic d'incidents et le suivi de la performance en production.

#### 4.3.2 Tests AutomatisÃ©s du ModÃ¨le (C12)

Tester un composant qui dÃ©pend d'une API externe payante pose un dÃ©fi. La solution est de l'isoler en utilisant la technique duÂ mocking. Le scriptÂ tests/test_llm_analyzer.pyÂ utilise le dÃ©corateurÂ @patchÂ de la bibliothÃ¨queÂ unittest.mockÂ pour remplacer l'appel rÃ©el Ã  l'API Gemini par une rÃ©ponse simulÃ©e et contrÃ´lÃ©e.

Cette approche permet de :

- Valider la logique interne de notre fonctionÂ analyze_textÂ (construction du prompt, traitement de la rÃ©ponse).

- ExÃ©cuter les tests rapidement et sans dÃ©pendance rÃ©seau.

- Ã‰viter tout coÃ»t liÃ© aux appels d'API pendant les tests.

- Garantir la reproductibilitÃ© des tests.

```
// Extrait de tests/test_llm_analyzer.py - CompÃ©tence C12
```

![](C:\Users\Ridab\AppData\Roaming\marktext\images\2025-07-09-15-07-21-image.png)

#### 4.3.3 ChaÃ®ne de Livraison Continue (C13)

Pour automatiser le processus de validation, une chaÃ®ne d'intÃ©gration continue a Ã©tÃ© mise en place avec GitHub Actions. Le fichier de configurationÂ .github/workflows/ci.ymlÂ dÃ©finit un workflow qui se dÃ©clenche Ã  chaque modification du code.

**Ã‰tapes du workflow :**

1. **Checkout :**Â RÃ©cupÃ©ration de la derniÃ¨re version du code.

2. **Setup Python :**Â Installation de l'environnement Python.

3. **Install Dependencies :**Â Installation de toutes les bibliothÃ¨ques listÃ©es dansÂ requirements.txt.

4. **Prepare Test Database :**Â ExÃ©cution du scriptÂ tests/setup_test_db.pyÂ pour crÃ©er une base de donnÃ©es de test propre.

5. **Run Tests :**Â Lancement de la suite de testsÂ pytest.

Si l'une de ces Ã©tapes Ã©choue, le workflow est marquÃ© comme "Ã©chouÃ©", empÃªchant l'intÃ©gration de code dÃ©fectueux.

![Capture dâ€™Ã©cran 2025-07-09 101207.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20101207.png)

![Capture dâ€™Ã©cran 2025-07-09 101324.png](C:\Users\Ridab\Pictures\Screenshots\capture%20projet%20simplon\Capture%20dâ€™Ã©cran%202025-07-09%20101324.png)

## 5. Ã‰preuves E4 & E5 : L'Application ComplÃ¨te (Bloc 3, C14-C21)

Pour rendre le service d'analyse accessible Ã  l'utilisateur final "Alex", j'ai dÃ©veloppÃ© une application web complÃ¨te avec Django. Cette application ne contient pas de logique mÃ©tier complexe ; son rÃ´le est d'agir en tant que client de l'API FastAPI. Cette approche met en Å“uvre une architecture microservices dÃ©couplÃ©e, une pratique standard dans l'industrie. Le cycle de vie de cette application est gÃ©rÃ© par des tests, une chaÃ®ne de livraison continue et une surveillance active, validant ainsi les compÃ©tences du Bloc 3.

### 5.1 DÃ©veloppement de l'Application Frontend (E4 : C16, C17)

#### 5.1.1 Conception de l'Application Django (C16)

La structure du projet respecte les conventions de Django pour garantir la clartÃ© et la maintenabilitÃ© :

- Un projet principalÂ dashboardÂ gÃ¨re la configuration globale.

- Une applicationÂ viewerÂ contient toute la logique de prÃ©sentation.

- Le routage est gÃ©rÃ© de maniÃ¨re hiÃ©rarchique :Â dashboard/urls.pyÂ dÃ©lÃ¨gue les requÃªtes Ã Â viewer/urls.pyÂ grÃ¢ce Ã  la fonctionÂ include(), ce qui permet une organisation modulaire du code.

#### 5.1.2 Vue Principale et Logique de Consommation d'API (C17)

La vueÂ viewer/views.pyÂ est le cÅ“ur de l'application frontend. Elle est responsable d'appeler les diffÃ©rents endpoints de l'API FastAPI, de collecter les donnÃ©es, et de les transmettre au template pour l'affichage. Une attention particuliÃ¨re a Ã©tÃ© portÃ©e Ã  la robustesse : un blocÂ try...exceptÂ global gÃ¨re les erreurs de communication avec l'API, garantissant que l'application ne plante pas si le backend est indisponible.

```
// Extrait de viewer/views.py - CompÃ©tences C10, C17
from django.shortcuts import render
import requests
import logging

logger = logging.getLogger(__name__)
API_BASE_URL = "http://127.0.0.1:8001"

def news_list(request):
    """    RÃ©cupÃ¨re toutes les donnÃ©es de l'API FastAPI pour les afficher sur un tableau de bord.    """
    logger.info(f"RequÃªte reÃ§ue pour le tableau de bord depuis l'IP : {request.META.get('REMOTE_ADDR')}")
    context = {
        'news_list': [],
        'price_history': [],
        'price_analysis': "Analyse non disponible.",
        'error_message': None
    }

    try:
        # Appels successifs aux endpoints de l'API backend
        news_response = requests.get(f"{API_BASE_URL}/latest-news?limit=5", timeout=5)
        news_response.raise_for_status()
        context['news_list'] = news_response.json()

        history_response = requests.get(f"{API_BASE_URL}/price-history?limit=24", timeout=5)
        history_response.raise_for_status()
        context['price_history'] = history_response.json()

        analysis_response = requests.get(f"{API_BASE_URL}/price-analysis", timeout=15)
        analysis_response.raise_for_status()
        context['price_analysis'] = analysis_response.json().get('analysis', "Format d'analyse inattendu.")

    except requests.exceptions.RequestException as e:
        # Gestion centralisÃ©e des erreurs de communication avec le backend
        error_message = f"Erreur de communication avec l'API backend : {e}"
        logger.error(error_message, exc_info=True)
        context['error_message'] = "Le service d'analyse est actuellement indisponible. Veuillez rÃ©essayer plus tard."

    return render(request, 'viewer/news_list.html', context)
```

#### 5.1.3 Interface Utilisateur avec les Templates Django (C17)


Le template viewer/templates/viewer/news_list.html utilise non seulement le langage de template de Django pour afficher les donnÃ©es de maniÃ¨re dynamique, mais intÃ¨gre Ã©galement un design CSS moderne pour amÃ©liorer significativement l'expÃ©rience utilisateur (UX).

- **Structure et Design :** L'interface est structurÃ©e en "cartes" (cards) disposÃ©es sur une grille, ce qui permet de segmenter clairement l'information (Analyse IA, ActualitÃ©s, Historique des Prix). L'utilisation d'icÃ´nes (via Font Awesome) et d'une typographie soignÃ©e renforce la lisibilitÃ©.
- **Logique d'Affichage :** Le template intÃ¨gre des structures de contrÃ´le avancÃ©es comme `{% for ... %}` avec `{% empty %}` pour gÃ©rer Ã©lÃ©gamment les cas oÃ¹ aucune donnÃ©e n'est disponible, et `{% if error_message %}` pour afficher des messages d'erreur clairs et stylisÃ©s Ã  l'utilisateur.
- **Formatage des DonnÃ©es :** Pour amÃ©liorer l'accessibilitÃ© de l'information, les donnÃ©es brutes comme les timestamps Unix sont prÃ©-traitÃ©es dans la vue Django avant d'Ãªtre envoyÃ©es au template. Elles sont ainsi affichÃ©es sous une forme lisible et comprÃ©hensible par l'utilisateur (ex: `09 Jul 2025, 10:21`).
  Ce travail dÃ©montre la capacitÃ© Ã  crÃ©er une interface non seulement fonctionnelle mais aussi esthÃ©tique et intuitive, en respectant les standards du web moderne.

```
//Interface Utilisateur Django
```

![](C:\Users\Ridab\AppData\Roaming\marktext\images\2025-07-09-16-04-59-image.png)

### 5.2 Tests, Packaging et Livraison Continue (E4 : C18, C19)

#### 5.2.1 Automatisation des Tests d'API (C18)

Pour garantir que l'API FastAPI fonctionne comme prÃ©vu, des tests d'intÃ©gration ont Ã©tÃ© Ã©crits dansÂ tests/test_api.py. Ces tests utilisent leÂ TestClientÂ de FastAPI pour simuler des requÃªtes HTTP vers les endpoints et valider leurs rÃ©ponses. Crucialement, ces tests s'exÃ©cutent contre une base de donnÃ©es de test dÃ©diÃ©e et isolÃ©e (crÃ©Ã©e parÂ tests/setup_test_db.py), ce qui garantit des rÃ©sultats fiables et reproductibles sans affecter les donnÃ©es de dÃ©veloppement.

```
// Extrait de tests/test_api.py - CompÃ©tence C18
from fastapi.testclient import TestClient
from api.app import app
import os

# Forcer l'API Ã  utiliser la base de donnÃ©es de test
import api.app
TEST_DB_PATH = os.path.join(os.path.dirname(__file__), 'test_database.db')
api.app.DB_PATH = TEST_DB_PATH

client = TestClient(app)

def test_get_latest_news():
    """Teste si l'API retourne bien la nouvelle de test."""
    response = client.get("/latest-news")
    assert response.status_code == 200
    data = response.json()
    assert len(data) == 1
    assert data[0]['title'] == "Titre de test"
```

#### 5.2.2 Packaging avec Docker pour la Livraison Continue (C19)

Pour finaliser le processus de livraison, l'API FastAPI a Ã©tÃ© packagÃ©e dans une image Docker. LeÂ dockerfileÂ est optimisÃ© pour la production :

- Il utilise une image de base lÃ©gÃ¨re (python:3.11-slim).

- Il sÃ©pare la copie et l'installation des dÃ©pendances du reste du code pour tirer parti du cache Docker.

- Il expose le port de l'application et dÃ©finit la commande de dÃ©marrage du serveur.

```
# Extrait du dockerfile - CompÃ©tence C19

# Ã‰tape 1: Partir d'une image Python officielle et lÃ©gÃ¨re
FROM python:3.11-slim

# Ã‰tape 2: DÃ©finir le rÃ©pertoire de travail
WORKDIR /app

# Ã‰tape 3: Copier uniquement le fichier des dÃ©pendances pour optimiser le cache
COPY requirements.txt .

# Ã‰tape 4: Installer les dÃ©pendances
RUN pip install --no-cache-dir -r requirements.txt

# Ã‰tape 5: Copier tout le reste du code
COPY . .

# Ã‰tape 6: Exposer le port que l'API utilisera
EXPOSE 8001

# Ã‰tape 7: La commande Ã  exÃ©cuter au dÃ©marrage
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8001"]
```

Ce conteneur est un artefact standard, portable et prÃªt Ã  Ãªtre dÃ©ployÃ© sur n'importe quel environnement, complÃ©tant ainsi la chaÃ®ne de livraison continue.

### 5.3 Surveillance et RÃ©solution d'Incidents (E5 : C20, C21)

#### 5.3.1 Surveillance de l'Application (C20)

En plus du monitoring du backend, une journalisation a Ã©tÃ© implÃ©mentÃ©e dans l'application frontend Django. La vue principale logue les requÃªtes entrantes des utilisateurs ainsi que les appels sortants vers l'API FastAPI. Cela permet d'avoir une traÃ§abilitÃ© complÃ¨te du parcours d'une requÃªte, de l'utilisateur final jusqu'au service d'IA, ce qui est indispensable pour le diagnostic en production.

**Preuve de logging (Extrait deÂ docs/exemples_de_logs.txt) :**

```
// Logs gÃ©nÃ©rÃ©s par Django lors d'une requÃªte utilisateur
RequÃªte reÃ§ue pour le tableau de bord depuis l'IP : 127.0.0.1
DÃ©but de l'appel API vers : http://127.0.0.1:8001/latest-news?limit=5
SuccÃ¨s : 3 actualitÃ©s rÃ©cupÃ©rÃ©es.
DÃ©but de l'appel API vers : http://127.0.0.1:8001/price-history?limit=24
SuccÃ¨s : 24 points d'historique rÃ©cupÃ©rÃ©s.
DÃ©but de l'appel API vers : http://127.0.0.1:8001/price-analysis
SuccÃ¨s : Analyse de l'IA rÃ©cupÃ©rÃ©e.
```



#### 5.3.2 RÃ©solution d'Incidents Techniques (C21)

Le dÃ©veloppement d'une architecture multi-services a prÃ©sentÃ© des dÃ©fis concrets. La capacitÃ© Ã  diagnostiquer et rÃ©soudre ces incidents est une compÃ©tence fondamentale. Deux exemples significatifs sont documentÃ©s ci-dessous.

**Incident 1 : Conflit de Port entre Services**

- **Contexte :**Â Lors du premier lancement simultanÃ© de Django et FastAPI, l'application frontend ne parvenait pas Ã  contacter le backend.

- **SymptÃ´me :**Â Les logs de Django affichaient uneÂ requests.exceptions.ConnectionError.

- **Diagnostic :**Â Une analyse rapide a montrÃ© que les deux serveurs tentaient d'utiliser le port 8000 par dÃ©faut, crÃ©ant une collision qui empÃªchait l'un des deux de dÃ©marrer correctement.

- **RÃ©solution :**Â Le serveur FastAPI a Ã©tÃ© explicitement lancÃ© sur le port 8001 via la commandeÂ uvicorn api.app:app --port 8001. L'URL de base dans la vue Django a Ã©tÃ© mise Ã  jour en consÃ©quence.

- **LeÃ§on Apprise :**Â Cet incident m'a appris l'importance de la configuration explicite et de la documentation de la topologie rÃ©seau, mÃªme dans un projet local, pour Ã©viter les conflits dans une architecture microservices.

**Incident 2 : Erreur d'Environnement dans la CI/CD**

- **Contexte :**Â Le premier workflow GitHub Actions Ã©chouait systÃ©matiquement, alors que tous les tests passaient en local.

- **SymptÃ´me :**Â Les logs du runner GitHub affichaient une erreurÂ ModuleNotFoundError: No module named 'httpx'.

- **Diagnostic :**Â L'erreur indiquait que l'environnement de la CI ne disposait pas de toutes les dÃ©pendances nÃ©cessaires. Le paquetÂ httpxÂ (une dÃ©pendance deÂ fastapi.testclient) avait Ã©tÃ© installÃ© manuellement en local mais n'avait pas Ã©tÃ© ajoutÃ© au fichierÂ requirements.txt.

- **RÃ©solution :**Â La dÃ©pendance manquante a Ã©tÃ© ajoutÃ©e au fichierÂ requirements.txt. AprÃ¨s un nouveau commit, le workflow s'est exÃ©cutÃ© avec succÃ¨s.

- **LeÃ§on Apprise :**Â Cet incident a Ã©tÃ© une dÃ©monstration pratique de la valeur de l'intÃ©gration continue. Elle force la discipline dans la gestion des dÃ©pendances et garantit la reproductibilitÃ© des environnements, Ã©vitant ainsi le classique "Ã§a marche sur ma machine".

## 6. Conclusion

Ce projet, "Bitcoin Analyzer", a permis de construire de bout en bout une application full-stack et pilotÃ©e par l'IA, en respectant les standards professionnels de dÃ©veloppement logiciel. Allant bien au-delÃ  d'un simple prototype, le rÃ©sultat est un service robuste, testÃ©, documentÃ© et prÃªt Ã  Ãªtre dÃ©ployÃ©, qui valide l'ensemble des compÃ©tences requises par le titre de DÃ©veloppeur en Intelligence Artificielle.

### 6.1 Bilan du Projet et Couverture des CompÃ©tences

L'objectif initial, qui Ã©tait de fournir une information financiÃ¨re centralisÃ©e et analysÃ©e, a Ã©tÃ© pleinement atteint. L'architecture dÃ©couplÃ©e, sÃ©parant le backend FastAPI du frontend Django, a prouvÃ© sa pertinence en permettant un dÃ©veloppement modulaire et une gestion claire des responsabilitÃ©s. L'intÃ©gration d'un service d'IA (Google Gemini), sÃ©lectionnÃ© aprÃ¨s une analyse rigoureuse, a permis d'ajouter une valeur mÃ©tier significative aux donnÃ©es brutes.

Le projet couvre de maniÃ¨re exhaustive les compÃ©tences du rÃ©fÃ©rentiel RNCP37827 :

| Bloc de CompÃ©tences                 | CompÃ©tences ValidÃ©es | Preuves ConcrÃ¨tes dans le Projet                                                                                                                             |
| ----------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Bloc 1 : La ChaÃ®ne de la DonnÃ©e** | C1-C5                | Scripts de collecte multi-sources (api, web, sql), modÃ©lisation de la BDD, et exposition via une API REST documentÃ©e (Swagger UI).                           |
| **Bloc 2 : IntÃ©gration de l'IA**    | C6-C13               | Documents de veille et de benchmark, intÃ©gration de Gemini, tests unitaires avec "mocking", et pipeline de CI/CD avec GitHub Actions.                        |
| **Bloc 3 : Application & MLOps**    | C14-C21              | Conception de l'application Django, consommation de l'API, packaging avec Docker, surveillance via logging, et rÃ©solution documentÃ©e d'incidents techniques. |

L'approche adoptÃ©e, axÃ©e sur les tests automatisÃ©s, l'intÃ©gration continue et la rÃ©solution mÃ©thodique d'incidents, dÃ©montre une maÃ®trise des pratiques MLOps et DevOps essentielles pour garantir la qualitÃ© et la maintenabilitÃ© d'un produit d'IA en conditions rÃ©elles.

### 6.2 Perspectives d'Ã‰volution

Le projet a Ã©tÃ© conÃ§u pour Ãªtre une fondation solide. Plusieurs axes d'Ã©volution sont envisagÃ©s pour l'avenir, dÃ©montrant une vision Ã  long terme du cycle de vie de l'application :

- **MontÃ©e en charge et Performance :**
  
  - **Base de DonnÃ©es :**Â Migration de SQLite vers un SGBD plus robuste comme PostgreSQL pour gÃ©rer un plus grand volume de donnÃ©es et des requÃªtes plus complexes.
  
  - **Caching :**Â ImplÃ©mentation d'un systÃ¨me de cache avec Redis pour les endpoints les plus sollicitÃ©s de l'API afin de rÃ©duire la latence et le nombre d'appels Ã  la base de donnÃ©es.

- **SÃ©curitÃ© et FiabilitÃ© :**
  
  - **Authentification :**Â SÃ©curisation de l'API avec un systÃ¨me d'authentification comme OAuth2 pour contrÃ´ler l'accÃ¨s aux endpoints.
  
  - **DÃ©ploiement Professionnel :**Â DÃ©ploiement de l'image Docker de l'API sur un service de conteneurisation cloud (ex: AWS Fargate, Google Cloud Run) et dÃ©ploiement de l'application Django, le tout intÃ©grÃ© au pipeline de CI/CD pour un dÃ©ploiement continu.

- **FonctionnalitÃ©s MÃ©tier :**
  
  - **Analyse AvancÃ©e :**Â EntraÃ®nement ou fine-tuning d'un modÃ¨le de langage spÃ©cialisÃ© sur des donnÃ©es financiÃ¨res pour fournir des analyses encore plus prÃ©cises et prÃ©dictives.
  
  - **InteractivitÃ© :**Â Ajout de graphiques interactifs sur le frontend pour une meilleure visualisation des donnÃ©es de marchÃ©.

Ce projet ne marque pas une fin, mais le dÃ©but d'un produit potentiellement viable, dont l'architecture a Ã©tÃ© pensÃ©e dÃ¨s le dÃ©part pour supporter ces Ã©volutions futures.
