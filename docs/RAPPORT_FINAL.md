# Rapport de Projet de Certification

**Titre du Projet :** Bitcoin Analyzer
**Candidat :** Ridab
**Certification Vis√©e :** RNCP37827 - D√©veloppeur en Intelligence Artificielle
**Date :** Juillet 2025

---

## Sommaire

1.  **Introduction et Analyse du Besoin (C14)**
2.  **Conception et Architecture Technique (C15)**
3.  **√âpreuve E1 : La Cha√Æne de la Donn√©e (Bloc 1, C1-C5)**
4.  **√âpreuves E2 & E3 : Int√©gration du Service d'IA (Bloc 2, C6-C13)**
5.  **√âpreuves E4 & E5 : L'Application Compl√®te (Bloc 3, C14-C21)**
6.  **Conclusion**

---

## 1. Introduction et Analyse du Besoin (Comp√©tence C14)

## 1. Contexte et Vision du Projet

Le march√© des cryptomonnaies, et en particulier du Bitcoin, est caract√©ris√© par une forte volatilit√© et un flux d'informations constant et dispers√©. Pour un investisseur non-expert, il est difficile de se forger une opinion √©clair√©e sans passer des heures √† agr√©ger et analyser des donn√©es de sources multiples.

**Vision :** "Bitcoin Analyzer" a pour but de devenir le tableau de bord de r√©f√©rence pour les investisseurs amateurs, en centralisant les donn√©es de march√©, les actualit√©s pertinentes et en fournissant une analyse de tendance simplifi√©e gr√¢ce √† l'Intelligence Artificielle. L'objectif est de rendre l'information financi√®re sur le Bitcoin **accessible, digeste et actionnable**.

## 2. Persona Utilisateur Cible

Pour guider la conception, nous d√©finissons un persona utilisateur principal.

### **üë§ Alex, 30 ans - L'Investisseur Prudent**

*   **Biographie :** Alex travaille dans le marketing et s'int√©resse aux nouvelles technologies. Il a investi une petite partie de ses √©conomies dans le Bitcoin mais n'a ni le temps ni l'expertise pour suivre les analyses financi√®res complexes.
*   **Besoins et Objectifs :**
    *   Comprendre rapidement la "temp√©rature" du march√© chaque jour.
    *   Acc√©der aux nouvelles importantes qui pourraient influencer le cours.
    *   Visualiser la tendance r√©cente sans avoir √† lire des graphiques complexes.
*   **Frustrations actuelles :**
    *   "Je suis noy√© sous le jargon technique sur Twitter et les sites sp√©cialis√©s."
    *   "Je ne sais pas si une news est r√©ellement importante ou si c'est juste du bruit."
    *   "Les graphiques de trading sont trop intimidants pour moi."

## 3. R√©cits Utilisateurs (User Stories)

Les fonctionnalit√©s de l'application sont d√©finies par les besoins de notre persona, Alex.

---

### **ID : US-01 - Consultation des Actualit√©s Centralis√©es**

*   **En tant que** Alex, l'investisseur prudent,
*   **Je veux** consulter les titres des derni√®res actualit√©s sur une seule et m√™me page,
*   **Afin de** me tenir inform√© rapidement des √©v√©nements majeurs sans avoir √† visiter plusieurs sites.

**Crit√®res d'Acceptation :**
*   Le tableau de bord doit afficher les 5 derni√®res actualit√©s.
*   Chaque actualit√© doit afficher son titre complet.
*   Le titre de chaque actualit√© doit √™tre un lien cliquable qui redirige vers l'article original dans un nouvel onglet.
*   Si aucune actualit√© n'est disponible, un message clair ("Aucune actualit√© √† afficher.") doit appara√Ætre.

---

### **ID : US-02 - Acc√®s √† une Analyse Simplifi√©e par l'IA**

*   **En tant que** Alex,
*   **Je veux** lire une analyse de la tendance du march√© r√©dig√©e en langage simple et concis,
*   **Afin de** comprendre l'orientation g√©n√©rale du march√© (haussi√®re, baissi√®re, stable) sans n√©cessiter de connaissances en analyse technique.

**Crit√®res d'Acceptation :**
*   L'analyse doit √™tre g√©n√©r√©e par le service d'Intelligence Artificielle.
*   Le texte de l'analyse ne doit pas d√©passer 3 phrases pour rester concis.
*   L'analyse doit √™tre pr√©sent√©e dans une section clairement identifi√©e ("Analyse de l'IA").
*   **Accessibilit√© :** Le fond de la section d'analyse doit avoir un contraste de couleur suffisant avec le texte pour √™tre lisible (respect des normes WCAG AA).
*   En cas d'√©chec de la g√©n√©ration de l'analyse, la section ne doit pas s'afficher ou doit afficher un message d'erreur discret.

---

### **ID : US-03 - Visualisation de l'Historique R√©cent des Prix**

*   **En tant que** Alex,
*   **Je veux** voir un historique simple des prix de cl√¥ture des derni√®res 24 heures,
*   **Afin de** visualiser la volatilit√© r√©cente du Bitcoin de mani√®re factuelle.

**Crit√®res d'Acceptation :**
*   Le tableau de bord doit afficher une liste ou un tableau des prix de cl√¥ture.
*   Chaque entr√©e doit indiquer le timestamp (ou l'heure) et le prix.
*   La liste doit √™tre tri√©e de la plus r√©cente √† la plus ancienne.
*   Par d√©faut, les 24 derniers points de donn√©es horaires sont affich√©s.

## 4. Fonctionnalit√©s Hors P√©rim√®tre (Version 1.0)

Pour assurer une livraison rapide et cibl√©e, les fonctionnalit√©s suivantes ne sont pas incluses dans la version initiale :

*   Cr√©ation de comptes utilisateurs et authentification.
*   Personnalisation du tableau de bord.
*   Graphiques interactifs avanc√©s.
*   Syst√®me d'alertes par email ou notification.


## 2. Conception et Architecture Technique (Comp√©tence C15)

# Architecture Technique - Bitcoin Analyzer


## 2. Sch√©ma d'Architecture D√©taill√©


```mermaid
graph TD;
subgraph "Utilisateur Final"
    U[üë§ Alex, Investisseur]
end

subgraph "Frontend (Interface Utilisateur)"
    direction LR
    U -- "1. Requ√™te HTTP (Port 8000)" --> D[Serveur Django];
    D -- "5. Renvoi de la page HTML" --> U;
end

subgraph "Backend (Service d'Analyse)"
    direction LR
    D -- "2. Appel API REST (Port 8001)" --> F[API FastAPI];
    F -- "3a. Requ√™te SQL" --> DB[(üóÉÔ∏è Base de Donn√©es SQLite)];
    DB -- " " --> F;
    F -- "3b. Appel API Externe" --> G[API Google Gemini];
    G -- " " --> F;
    F -- "4. R√©ponse JSON" --> D;
end

style D fill:#A9D0F5,stroke:#333,stroke-width:2px
style F fill:#F5BCA9,stroke:#333,stroke-width:2px


**Description des flux :**
1.  L'utilisateur acc√®de au tableau de bord via son navigateur, envoyant une requ√™te au serveur **Django** sur le port 8000.
2.  La vue Django agit comme un client et envoie des requ√™tes HTTP √† l'API **FastAPI** sur le port 8001 pour obtenir les donn√©es (news, prix, analyse).
3.  L'API FastAPI orchestre la r√©cup√©ration des donn√©es :
a. Elle interroge la base de donn√©es **SQLite** pour les donn√©es de march√© et les actualit√©s.
b. Elle appelle l'API externe de **Google Gemini** pour g√©n√©rer l'analyse de tendance.
4.  FastAPI agr√®ge les r√©ponses et les retourne au format **JSON** √† Django.
5.  Django utilise ces donn√©es pour populer le template HTML et renvoie la page web compl√®te au navigateur de l'utilisateur.

## 3. Pile Technologique et Justification des Choix

Chaque technologie a √©t√© s√©lectionn√©e apr√®s une analyse de ses forces et de sa pertinence pour le projet, en consid√©rant √©galement des alternatives.

### Langage : Python 3.11
*   **Justification :** Choix naturel pour un projet d'IA gr√¢ce √† son √©cosyst√®me mature (Pandas, Scikit-learn pour des √©volutions futures) et ses excellentes biblioth√®ques pour le d√©veloppement web (`fastapi`, `django`) et l'acc√®s aux donn√©es (`requests`, `beautifulsoup4`). Sa syntaxe claire favorise un d√©veloppement rapide et une maintenance ais√©e.

### Backend : FastAPI
*   **Justification :**
*   **Haute Performance :** Bas√© sur Starlette et Pydantic, FastAPI est l'un des frameworks Python les plus rapides, id√©al pour une API qui se doit d'√™tre r√©active.
*   **Documentation Automatique (validation de C5) :** G√©n√®re nativement une documentation interactive (Swagger UI / OpenAPI), ce qui est un gain de temps majeur et une exigence de qualit√© professionnelle pour toute API.
*   **Validation des Donn√©es :** Utilise Pydantic pour une validation robuste et claire des types de donn√©es en entr√©e et en sortie, r√©duisant ainsi les bugs.
*   **Alternative √âcart√©e :**
*   **Flask :** Bien que plus l√©ger, Flask ne propose pas de validation de donn√©es ni de documentation automatique nativement. Les ajouter n√©cessiterait des biblioth√®ques tierces (ex: Flask-RESTful, Flasgger), complexifiant la maintenance et ajoutant des points de d√©faillance potentiels.
*   **Django REST Framework (DRF) :** Tr√®s puissant mais plus lourd et plus complexe √† configurer pour une API simple comme celle-ci. L'approche "tout-en-un" de DRF √©tait superflue, FastAPI offrant un meilleur √©quilibre performance/simplicit√© pour ce projet.

### Frontend : Django
*   **Justification :**
*   **Framework Complet ("Batteries included") :** Offre une structure robuste pour construire une application web compl√®te avec un ORM, un syst√®me de templates puissant, et des fonctionnalit√©s de s√©curit√© int√©gr√©es.
*   **D√©monstration de Comp√©tence :** Utiliser Django comme simple consommateur d'API d√©montre la ma√Ætrise des architectures d√©coupl√©es, une comp√©tence tr√®s recherch√©e dans le monde professionnel, qui valorise la s√©paration des responsabilit√©s.
*   **Alternative √âcart√©e :**
*   **Streamlit/Gradio :** Ces outils sont excellents pour des prototypes rapides de data science et des interfaces de d√©monstration de mod√®les. Cependant, ils offrent moins de contr√¥le sur le design (HTML/CSS) et la structure de l'application, les rendant moins adapt√©s pour construire une application web personnalisable et √©volutive destin√©e √† un utilisateur final.

### Base de Donn√©es : SQLite
*   **Justification :**
*   **Simplicit√© :** Aucune installation de serveur requise, la base de donn√©es est un simple fichier. C'est la solution parfaite pour le d√©veloppement, les tests automatis√©s et un d√©ploiement l√©ger.
*   **Int√©gration Python :** Fait partie de la biblioth√®que standard de Python, ne n√©cessitant aucune d√©pendance externe pour fonctionner.
*   **Vision d'√âvolution (Scalabilit√©) :** SQLite est suffisant pour la version 1 du projet. Pour une mise en production √† plus grande √©chelle, l'architecture est pens√©e pour une migration future. Le code d'acc√®s aux donn√©es √©tant bien isol√©, il serait ais√© de le remplacer par des appels √† un SGBD plus robuste comme **PostgreSQL**. Cette anticipation d√©montre une r√©flexion sur le cycle de vie complet de l'application.

### Service d'IA : Google Gemini Pro
*   **Justification :** Le choix de ce mod√®le n'est pas arbitraire. Il est le r√©sultat d'un benchmark formel document√© dans `docs/benchmark_ia.md`. Gemini Pro a √©t√© s√©lectionn√© car il offre le meilleur compromis entre :
1.  **Performance :** Un score Elo tr√®s comp√©titif sur la LMSys Chatbot Arena.
2.  **Co√ªt :** Un tarif tr√®s abordable, rendant le projet √©conomiquement viable.
3.  **Facilit√© d'int√©gration :** Une biblioth√®que Python officielle (`google-generativeai`) claire et bien document√©e.

## 3. √âpreuve E1 : La Cha√Æne de la Donn√©e (Bloc 1, C1-C5)


Pour alimenter l'application, j'ai mis en place une cha√Æne de traitement de la donn√©e compl√®te, fiable et automatis√©e. Cette cha√Æne couvre la collecte depuis des sources h√©t√©rog√®nes, le nettoyage, le stockage et la mise √† disposition via une API REST, validant ainsi l'ensemble des comp√©tences du Bloc 1.
3.1 Automatisation de l'Extraction Multi-sources (C1, C3)
La premi√®re √©tape a consist√© √† automatiser la collecte de donn√©es de natures diff√©rentes pour garantir une vision compl√®te du march√©.
Source 1 : API REST Externe (Coinalyze) - Comp√©tence C1
Pour obtenir les donn√©es de march√© financi√®res (prix, volume), j'ai d√©velopp√© le script scripts/extraction_api.py. Il interroge l'API de Coinalyze de mani√®re robuste et s√©curis√©e. La s√©curit√© des informations d'authentification a √©t√© une priorit√© : la cl√© API est stock√©e dans un fichier .env (exclu du contr√¥le de version via .gitignore) et charg√©e dynamiquement en m√©moire gr√¢ce √† la biblioth√®que python-dotenv.
Generated python
// Extrait de scripts/extraction_api.py
import os
import requests
import time
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("COINALYZE_API")
API_URL = "https://api.coinalyze.net/v1/ohlcv-history"

def get_bitcoin_data():
    """
    Interroge l'API Coinalyze pour r√©cup√©rer les donn√©es OHLCV
    des derni√®res 24 heures et g√®re les erreurs de connexion.
    """
    params = {
        "symbols": "BTCUSDC.A",
        "interval": "1hour",
        "from": int(time.time()) - (24 * 60 * 60),
        "to": int(time.time())
    }
    headers = {"api_key" : API_KEY}
    
    response = requests.get(API_URL, headers=headers, params=params)
    if response.status_code == 200:
        print("Connexion √† l'API Coinalyze r√©ussie !")
        data = response.json()
        return data
    else:
        print(f"Erreur {response.status_code} : {response.text}")
        return None
Use code with caution.
Python
Source 2 : Scraping Web Dynamique (news.bitcoin.com) - Comp√©tence C1
Pour les actualit√©s, la source initiale s'est av√©r√©e trop prot√©g√©e contre le scraping classique. J'ai donc d√©velopp√© une nouvelle version du script `scripts/extraction_news.py` qui cible `news.bitcoin.com`. Ce site charge son contenu dynamiquement via JavaScript, rendant une simple requ√™te HTTP inefficace. La solution a donc √©t√© d'utiliser `undetected-chromedriver` pour piloter un v√©ritable navigateur Chrome. Le script attend que le JavaScript s'ex√©cute, puis il parse le HTML final avec `BeautifulSoup`. Cette approche robuste permet d'extraire les titres et les liens des articles, transformant des donn√©es non structur√©es et dynamiques en un format structur√© et exploitable. La gestion de cet incident est d√©taill√©e dans la section C21.
Agr√©gation et Nettoyage - Comp√©tence C3
Une fois les donn√©es brutes extraites, elles sont imm√©diatement nettoy√©es et format√©es pour garantir leur qualit√© et leur homog√©n√©it√© avant le stockage. Par exemple, dans extraction_api.py, les donn√©es JSON de l'API sont transform√©es en une liste de dictionnaires Python avec des cl√©s normalis√©es (timestamp, open, high, low, close, volume), pr√©parant ainsi le jeu de donn√©es final.
3.2 Extraction via Requ√™tes SQL (C2)
Pour d√©montrer la capacit√© √† interagir avec des syst√®mes d'information existants (un cas tr√®s courant en entreprise), j'ai simul√© une base de donn√©es "legacy" et d√©velopp√© un script pour en extraire les donn√©es via des requ√™tes SQL standard.
D'abord, le script scripts/setup_source_db.py cr√©e une base de donn√©es source_data.db contenant une table legacy_articles.
Ensuite, le script scripts/extraction_sql.py se connecte √† cette base source et ex√©cute une requ√™te SQL SELECT pour r√©cup√©rer les articles.
Generated python
// Extrait de scripts/extraction_sql.py - Comp√©tence C2
import sqlite3

# Connexion √† la base de donn√©es source
source_conn = sqlite3.connect("data/source_data.db")
source_cursor = source_conn.cursor()

# La requ√™te SQL d'extraction des donn√©es depuis le syst√®me legacy
query = "SELECT article_title, article_url FROM legacy_articles;"
source_cursor.execute(query)

articles_from_source = source_cursor.fetchall()
source_conn.close()

# Les donn√©es sont ensuite trait√©es et ins√©r√©es dans la base principale
# ...
Use code with caution.
Python
Cette approche valide la ma√Ætrise de l'extraction de donn√©es depuis un SGBD via le langage SQL.
3.3 Stockage et Mod√©lisation des Donn√©es (C4)
Toutes les donn√©es collect√©es et nettoy√©es sont centralis√©es dans une base de donn√©es SQLite unique, data/bitcoin.db. Le module scripts/stockage.py est responsable de la cr√©ation de la base et de la d√©finition du sch√©ma des tables.
Pour garantir l'int√©grit√© des donn√©es et l'idempotence des scripts de collecte (c'est-√†-dire qu'on peut les lancer plusieurs fois sans cr√©er de doublons), des contraintes UNIQUE ont √©t√© plac√©es sur les champs cl√©s.
Generated sql
// Sch√©ma SQL d√©fini dans scripts/stockage.py - Comp√©tence C4
-- Cr√©ation de la table pour les prix du Bitcoin
CREATE TABLE IF NOT EXISTS bitcoin_prices (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp INTEGER UNIQUE, -- Cl√© unique pour √©viter les doublons de prix
    open REAL,
    high REAL,
    low REAL,
    close REAL,
    volume REAL
);

-- Cr√©ation de la table pour les actualit√©s
CREATE TABLE IF NOT EXISTS bitcoin_news (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL UNIQUE, -- Cl√© unique pour √©viter les doublons de news
    link TEXT NOT NULL,
    content TEXT,
    timestamp DATETIME
);
Use code with caution.
SQL
Cette mod√©lisation rigoureuse assure la fiabilit√© et la coh√©rence du jeu de donn√©es qui alimentera l'application.
3.4 Exposition des Donn√©es via une API REST (C5)
La derni√®re √©tape du Bloc 1 consiste √† rendre les donn√©es stock√©es accessibles de mani√®re programmatique. J'ai d√©velopp√© pour cela une API en utilisant le framework FastAPI, choisi pour sa performance et sa capacit√© √† g√©n√©rer automatiquement une documentation conforme au standard OpenAPI.
L'API, d√©finie dans api/app.py, expose plusieurs endpoints, dont :
/latest-news : pour r√©cup√©rer les derni√®res actualit√©s.
/price-history : pour obtenir l'historique des prix.
L'un des livrables les plus importants de cette comp√©tence est la documentation interactive (Swagger UI) g√©n√©r√©e automatiquement par FastAPI. Elle permet √† n'importe quel d√©veloppeur (ou au jury) de comprendre et de tester l'API sans avoir √† lire une ligne de code, ce qui est une pratique professionnelle essentielle.
[INSTRUCTION : Ins√©rez ici une capture d'√©cran de votre interface Swagger UI, accessible √† l'adresse /docs de votre API en cours d'ex√©cution. Montrez les endpoints /latest-news et /price-history d√©pli√©s.]

## 4. √âpreuves E2 & E3 : Int√©gration du Service d'IA (Bloc 2, C6-C13)

Une fois la cha√Æne de donn√©es √©tablie, le c≈ìur du projet a √©t√© d'enrichir ces donn√©es gr√¢ce √† un service d'intelligence artificielle. Ce bloc d√©montre une approche professionnelle compl√®te : de la veille technologique √† la s√©lection du mod√®le, son int√©gration, son exposition via une API, et enfin, la mise en place de tests et d'une cha√Æne de livraison continue pour garantir sa fiabilit√©.
4.1 Veille, Benchmark et S√©lection du Service (E2 : C6, C7, C8)
Le choix d'un service d'IA ne doit pas √™tre arbitraire. Il doit r√©sulter d'une analyse rigoureuse de l'√©tat de l'art et des contraintes du projet.
4.1.1 Veille Technologique Active (C6)
Pour garantir que le projet utilise des technologies pertinentes et des pratiques √† jour, une veille technologique active a √©t√© men√©e. Plut√¥t qu'une simple lecture passive, la m√©thodologie s'est concentr√©e sur des sources primaires et des discussions techniques :
Suivi de D√©p√¥ts GitHub Cl√©s : Surveillance active des issues, discussions et releases de projets comme google/generative-ai-python et tiangolo/fastapi.
Consultation de Listes "Awesome" : Suivi r√©gulier de listes communautaires comme awesome-generative-ai pour d√©couvrir de nouveaux outils.
Analyse de Plateformes Techniques : Participation aux discussions sur Hacker News et Reddit (r/MachineLearning).
Cette veille, document√©e dans docs/veille_technologique.md, a permis d'identifier des opportunit√©s concr√®tes. Par exemple, la d√©couverte de la biblioth√®que litellm a √©t√© not√©e comme une piste d'√©volution int√©ressante pour une future V2 du projet afin de supporter plusieurs mod√®les d'IA de mani√®re unifi√©e.
4.1.2 Benchmark et S√©lection du Mod√®le d'IA (C7)
Le choix du mod√®le de langage (LLM) a fait l'objet d'un benchmark formel et quantifi√©, d√©taill√© dans le document docs/benchmark_ia.md.
M√©thodologie :
Quatre mod√®les majeurs ont √©t√© √©valu√©s selon quatre crit√®res pond√©r√©s :
Qualit√© d'Analyse (40%) : Bas√©e sur le classement Elo de la LMSys Chatbot Arena, une r√©f√©rence communautaire objective.
Co√ªt de l'API (30%) : Prix par million de tokens, crucial pour la viabilit√© √©conomique.
Facilit√© d'Int√©gration (20%) : Qualit√© de la biblioth√®que Python et de la documentation.
Vitesse de R√©ponse (10%) : Impact sur l'exp√©rience utilisateur.
Tableau Comparatif Synth√©tique :
Crit√®re	Google Gemini Pro	OpenAI GPT-3.5-Turbo	Anthropic Claude 3 Sonnet
Score Elo LMSys	1,251 ü•à	1,207	1,278 ü•á
Co√ªt Total ($/M tokens)	$2.00 üí∞	$2.00 üí∞	$18.00
Score Pond√©r√© Final	95 / 100 üèÜ	95 / 100	75 / 100
D√©cision Finale : Google Gemini Pro
Bien que Claude 3 Sonnet ait le score de qualit√© le plus √©lev√©, son co√ªt est prohibitif pour ce projet. Google Gemini Pro a √©t√© s√©lectionn√© car il offre un rapport qualit√©/prix exceptionnel, avec un score Elo tr√®s proche du leader pour un co√ªt 9 fois inf√©rieur.
4.1.3 Param√©trage du Service (C8)
L'int√©gration du service Gemini Pro a √©t√© r√©alis√©e via la biblioth√®que Python officielle google-generativeai. Conform√©ment aux bonnes pratiques de s√©curit√©, la cl√© d'API a √©t√© configur√©e via une variable d'environnement, charg√©e par python-dotenv, garantissant qu'aucune information sensible n'est expos√©e dans le code source.
4.2 Exposition et Int√©gration du Mod√®le (E3 : C9, C10)
4.2.1 Exposition du Mod√®le via l'API (C9)
La valeur ajout√©e de l'IA est expos√©e via l'endpoint /price-analysis de l'API FastAPI. Cet endpoint ne se contente pas de relayer une requ√™te ; il met en ≈ìuvre une strat√©gie de prompt engineering pour maximiser la pertinence de la r√©ponse du LLM.
Le processus est le suivant :
R√©cup√©rer l'historique r√©cent des prix depuis la base de donn√©es SQLite.
Formatter ces donn√©es num√©riques en un texte descriptif et compr√©hensible.
Construire un prompt d√©taill√© qui assigne un r√¥le au mod√®le ("Tu es un analyste financier pour un d√©butant"), fournit le contexte (les donn√©es de prix) et sp√©cifie le format de la r√©ponse attendue (concise et en langage simple).
Appeler le module d'analyse IA avec ce prompt.
Retourner la r√©ponse textuelle du mod√®le dans un format JSON propre.
Generated python
// Extrait de api/app.py - Comp√©tence C9
@app.get("/price-analysis", summary="Obtenir une analyse IA de la tendance des prix")
def price_analysis(limit: int = 24):
    """
    Fournit une analyse textuelle de la tendance des prix du Bitcoin g√©n√©r√©e par une IA.
    """
    logging.info(f"Requ√™te re√ßue pour l'analyse de prix (limite={limit}).")
    try:
        # 1. R√©cup√©ration des donn√©es
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT timestamp, close FROM bitcoin_prices ORDER BY timestamp DESC LIMIT ?", (limit,))
            rows = cursor.fetchall()

        if not rows:
            raise HTTPException(status_code=404, detail="Pas assez de donn√©es pour l'analyse")

        # 2. Formatage des donn√©es pour le prompt
        formatted_history = "\n".join(
            [f"Date (timestamp {row[0]}): Prix de cl√¥ture = {row[1]}$" for row in rows]
        )
        
        # 3. Construction du prompt
        prompt = (
            "Tu es un analyste financier pour un d√©butant. "
            "Bas√© sur l'historique de prix du Bitcoin suivant, quelle est la tendance g√©n√©rale (haussi√®re, baissi√®re, ou stable) ? "
            "R√©ponds en 2 phrases maximum, en mentionnant si le march√© semble volatil ou non.\n\n"
            f"Donn√©es:\n{formatted_history}"
        )

        # 4. Appel au service d'analyse IA
        logging.info("Appel au service d'analyse IA (Gemini)...")
        analysis_result = analyze_text(prompt)
        logging.info("Analyse IA re√ßue avec succ√®s.")

        # 5. Retour de la r√©ponse
        return {"analysis": analysis_result}

    except Exception as e:
        logging.error(f"Erreur critique lors de l'analyse de prix : {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur interne du serveur lors de l'analyse IA")
Use code with caution.
Python
4.2.2 Int√©gration dans l'Application Frontend (C10)
Cette fonctionnalit√© d'IA est ensuite rendue accessible √† l'utilisateur final. L'application Django, agissant comme un client, envoie une requ√™te HTTP √† l'endpoint /price-analysis de l'API FastAPI pour r√©cup√©rer l'analyse et l'afficher sur le tableau de bord. Cette communication inter-services est une d√©monstration cl√© de l'architecture d√©coupl√©e du projet.
4.3 Monitoring, Tests et CI/CD du Service IA (E3 : C11, C12, C13)
Pour assurer la qualit√© et la robustesse du service d'IA, une approche MLOps a √©t√© adopt√©e, int√©grant le monitoring, les tests automatis√©s et la livraison continue.
4.3.1 Monitoring du Mod√®le (C11)
Le module logging de Python a √©t√© int√©gr√© dans l'API FastAPI pour tracer de mani√®re exhaustive toutes les interactions avec le service d'IA. Chaque appel √† l'endpoint /price-analysis g√©n√®re des logs qui permettent de suivre :
La r√©ception de la requ√™te.
Le d√©but de l'appel √† l'API externe de Gemini.
La r√©ception r√©ussie de la r√©ponse.
Toute erreur survenant durant le processus.
Preuve de logging (Extrait de docs/exemples_de_logs.txt) :
Generated code
2025-07-09 10:23:39,098 - INFO - API - Requ√™te re√ßue pour l'analyse de prix (limite=24).
2025-07-09 10:23:39,103 - INFO - API - Appel au service d'analyse IA (Gemini)...
2025-07-09 10:23:46,068 - INFO - API - Analyse IA re√ßue avec succ√®s.
INFO:     127.0.0.1:61446 - "GET /price-analysis HTTP/1.1" 200 OK
Use code with caution.
Ce monitoring est essentiel pour le diagnostic d'incidents et le suivi de la performance en production.
4.3.2 Tests Automatis√©s du Mod√®le (C12)
Tester un composant qui d√©pend d'une API externe payante pose un d√©fi. La solution est de l'isoler en utilisant la technique du mocking. Le script tests/test_llm_analyzer.py utilise le d√©corateur @patch de la biblioth√®que unittest.mock pour remplacer l'appel r√©el √† l'API Gemini par une r√©ponse simul√©e et contr√¥l√©e.
Cette approche permet de :
Valider la logique interne de notre fonction analyze_text (construction du prompt, traitement de la r√©ponse).
Ex√©cuter les tests rapidement et sans d√©pendance r√©seau.
√âviter tout co√ªt li√© aux appels d'API pendant les tests.
Garantir la reproductibilit√© des tests.
Generated python
// Extrait de tests/test_llm_analyzer.py - Comp√©tence C12
import pytest
from unittest.mock import patch, MagicMock
from scripts.llm_analyzer import analyze_text

@patch('scripts.llm_analyzer.genai.GenerativeModel')
def test_analyze_text_with_mock(mock_generative_model):
    """
    V√©rifie que notre fonction `analyze_text` appelle bien le mod√®le simul√©
    et retourne le texte de la r√©ponse attendue.
    """
    # 1. Pr√©paration : On configure la r√©ponse que le mock doit retourner
    fake_response_text = "Ceci est une analyse simul√©e r√©ussie."
    mock_model_instance = MagicMock()
    mock_model_instance.generate_content.return_value.text = fake_response_text
    mock_generative_model.return_value = mock_model_instance

    prompt_test = "Ceci est un prompt de test."

    # 2. Action : On appelle notre fonction
    result = analyze_text(prompt_test)

    # 3. V√©rification : On s'assure que le mock a √©t√© appel√© correctement
    # et que le r√©sultat est celui attendu.
    mock_model_instance.generate_content.assert_called_once_with(prompt_test)
    assert result == fake_response_text
Use code with caution.
Python
4.3.3 Cha√Æne de Livraison Continue (C13)
Pour automatiser le processus de validation, une cha√Æne d'int√©gration continue a √©t√© mise en place avec GitHub Actions. Le fichier de configuration .github/workflows/ci.yml d√©finit un workflow qui se d√©clenche √† chaque modification du code.
√âtapes du workflow :
Checkout : R√©cup√©ration de la derni√®re version du code.
Setup Python : Installation de l'environnement Python.
Install Dependencies : Installation de toutes les biblioth√®ques list√©es dans requirements.txt.
Prepare Test Database : Ex√©cution du script tests/setup_test_db.py pour cr√©er une base de donn√©es de test propre.
Run Tests : Lancement de la suite de tests pytest.
Si l'une de ces √©tapes √©choue, le workflow est marqu√© comme "√©chou√©", emp√™chant l'int√©gration de code d√©fectueux.
[INSTRUCTION : Ins√©rez ici une capture d'√©cran d'une ex√©cution r√©ussie de votre workflow sur GitHub Actions, montrant les diff√©rentes √©tapes (Setup, Install, Test) avec une coche verte.]

## 5. √âpreuves E4 & E5 : L'Application Compl√®te (Bloc 3, C14-C21)


Pour rendre le service d'analyse accessible √† l'utilisateur final "Alex", j'ai d√©velopp√© une application web compl√®te avec Django. Cette application ne contient pas de logique m√©tier complexe ; son r√¥le est d'agir en tant que client de l'API FastAPI. Cette approche met en ≈ìuvre une architecture microservices d√©coupl√©e, une pratique standard dans l'industrie. Le cycle de vie de cette application est g√©r√© par des tests, une cha√Æne de livraison continue et une surveillance active, validant ainsi les comp√©tences du Bloc 3.
5.1 D√©veloppement de l'Application Frontend (E4 : C16, C17)
5.1.1 Conception de l'Application Django (C16)
La structure du projet respecte les conventions de Django pour garantir la clart√© et la maintenabilit√© :
Un projet principal dashboard g√®re la configuration globale.
Une application viewer contient toute la logique de pr√©sentation.
Le routage est g√©r√© de mani√®re hi√©rarchique : dashboard/urls.py d√©l√®gue les requ√™tes √† viewer/urls.py gr√¢ce √† la fonction include(), ce qui permet une organisation modulaire du code.
5.1.2 Vue Principale et Logique de Consommation d'API (C17)
La vue viewer/views.py est le c≈ìur de l'application frontend. Elle est responsable d'appeler les diff√©rents endpoints de l'API FastAPI, de collecter les donn√©es, et de les transmettre au template pour l'affichage. Une attention particuli√®re a √©t√© port√©e √† la robustesse : un bloc try...except global g√®re les erreurs de communication avec l'API, garantissant que l'application ne plante pas si le backend est indisponible.
Generated python
// Extrait de viewer/views.py - Comp√©tences C10, C17
from django.shortcuts import render
import requests
import logging

logger = logging.getLogger(__name__)
API_BASE_URL = "http://127.0.0.1:8001"

def news_list(request):
    """
    R√©cup√®re toutes les donn√©es de l'API FastAPI pour les afficher sur un tableau de bord.
    """
    logger.info(f"Requ√™te re√ßue pour le tableau de bord depuis l'IP : {request.META.get('REMOTE_ADDR')}")
    context = {
        'news_list': [],
        'price_history': [],
        'price_analysis': "Analyse non disponible.",
        'error_message': None
    }

    try:
        # Appels successifs aux endpoints de l'API backend
        news_response = requests.get(f"{API_BASE_URL}/latest-news?limit=5", timeout=5)
        news_response.raise_for_status()
        context['news_list'] = news_response.json()

        history_response = requests.get(f"{API_BASE_URL}/price-history?limit=24", timeout=5)
        history_response.raise_for_status()
        context['price_history'] = history_response.json()

        analysis_response = requests.get(f"{API_BASE_URL}/price-analysis", timeout=15)
        analysis_response.raise_for_status()
        context['price_analysis'] = analysis_response.json().get('analysis', "Format d'analyse inattendu.")

    except requests.exceptions.RequestException as e:
        # Gestion centralis√©e des erreurs de communication avec le backend
        error_message = f"Erreur de communication avec l'API backend : {e}"
        logger.error(error_message, exc_info=True)
        context['error_message'] = "Le service d'analyse est actuellement indisponible. Veuillez r√©essayer plus tard."

    return render(request, 'viewer/news_list.html', context)
Use code with caution.
Python
5.1.3 Interface Utilisateur avec les Templates Django (C17)
Le template viewer/templates/viewer/news_list.html utilise le langage de template de Django pour afficher les donn√©es de mani√®re dynamique. Il int√®gre des structures de contr√¥le ({% for %}, {% if %}) pour s'adapter √† la pr√©sence ou √† l'absence de donn√©es et pour afficher des messages d'erreur clairs √† l'utilisateur.
Generated html
<!-- Extrait de viewer/templates/viewer/news_list.html -->
{% if error_message %}
    <p class="error">{{ error_message }}</p>
{% endif %}

<div class="card">
    <h2>Derni√®res Actualit√©s</h2>
    {% for article in news_list %}
        <div class="article">
            <h3><a href="{{ article.link }}" target="_blank">{{ article.title }}</a></h3>
        </div>
    {% empty %}
        <p>Aucune actualit√© √† afficher.</p>
    {% endfor %}
</div>
Use code with caution.
Html
5.2 Tests, Packaging et Livraison Continue (E4 : C18, C19)
5.2.1 Automatisation des Tests d'API (C18)
Pour garantir que l'API FastAPI fonctionne comme pr√©vu, des tests d'int√©gration ont √©t√© √©crits dans tests/test_api.py. Ces tests utilisent le TestClient de FastAPI pour simuler des requ√™tes HTTP vers les endpoints et valider leurs r√©ponses. Crucialement, ces tests s'ex√©cutent contre une base de donn√©es de test d√©di√©e et isol√©e (cr√©√©e par tests/setup_test_db.py), ce qui garantit des r√©sultats fiables et reproductibles sans affecter les donn√©es de d√©veloppement.
Generated python
// Extrait de tests/test_api.py - Comp√©tence C18
from fastapi.testclient import TestClient
from api.app import app

# Forcer l'API √† utiliser la base de donn√©es de test
import api.app
TEST_DB_PATH = os.path.join(os.path.dirname(__file__), 'test_database.db')
api.app.DB_PATH = TEST_DB_PATH

client = TestClient(app)

def test_get_latest_news():
    """Teste si l'API retourne bien la nouvelle de test."""
    response = client.get("/latest-news")
    assert response.status_code == 200
    data = response.json()
    assert len(data) == 1
    assert data[0]['title'] == "Titre de test"
Use code with caution.
Python
5.2.2 Packaging avec Docker pour la Livraison Continue (C19)
Pour finaliser le processus de livraison, l'API FastAPI a √©t√© packag√©e dans une image Docker. Le dockerfile est optimis√© pour la production :
Il utilise une image de base l√©g√®re (python:3.11-slim).
Il s√©pare la copie et l'installation des d√©pendances du reste du code pour tirer parti du cache Docker.
Il expose le port de l'application et d√©finit la commande de d√©marrage du serveur.
Generated dockerfile
# Extrait du dockerfile - Comp√©tence C19
# √âtape 1: Partir d'une image Python officielle et l√©g√®re
FROM python:3.11-slim

# √âtape 2: D√©finir le r√©pertoire de travail
WORKDIR /app

# √âtape 3: Copier uniquement le fichier des d√©pendances pour optimiser le cache
COPY requirements.txt .

# √âtape 4: Installer les d√©pendances
RUN pip install --no-cache-dir -r requirements.txt

# √âtape 5: Copier tout le reste du code
COPY . .

# √âtape 6: Exposer le port que l'API utilisera
EXPOSE 8001

# √âtape 7: La commande √† ex√©cuter au d√©marrage
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8001"]
Use code with caution.
Dockerfile
Ce conteneur est un artefact standard, portable et pr√™t √† √™tre d√©ploy√© sur n'importe quel environnement, compl√©tant ainsi la cha√Æne de livraison continue.
5.3 Surveillance et R√©solution d'Incidents (E5 : C20, C21)
5.3.1 Surveillance de l'Application (C20)
En plus du monitoring du backend, une journalisation a √©t√© impl√©ment√©e dans l'application frontend Django. La vue principale logue les requ√™tes entrantes des utilisateurs ainsi que les appels sortants vers l'API FastAPI. Cela permet d'avoir une tra√ßabilit√© compl√®te du parcours d'une requ√™te, de l'utilisateur final jusqu'au service d'IA, ce qui est indispensable pour le diagnostic en production.
Preuve de logging (Extrait de docs/exemples_de_logs.txt) :
Generated code
// Logs g√©n√©r√©s par Django lors d'une requ√™te utilisateur
Requ√™te re√ßue pour le tableau de bord depuis l'IP : 127.0.0.1
D√©but de l'appel API vers : http://127.0.0.1:8001/latest-news?limit=5
Succ√®s : 3 actualit√©s r√©cup√©r√©es.
D√©but de l'appel API vers : http://127.0.0.1:8001/price-history?limit=24
Succ√®s : 24 points d'historique r√©cup√©r√©s.
D√©but de l'appel API vers : http://127.0.0.1:8001/price-analysis
Succ√®s : Analyse de l'IA r√©cup√©r√©e.
Use code with caution.
5.3.2 R√©solution d'Incidents Techniques (C21)
Le d√©veloppement d'une architecture multi-services a pr√©sent√© des d√©fis concrets. La capacit√© √† diagnostiquer et r√©soudre ces incidents est une comp√©tence fondamentale. Deux exemples significatifs sont document√©s ci-dessous.
Incident 1 : Conflit de Port entre Services
Contexte : Lors du premier lancement simultan√© de Django et FastAPI, l'application frontend ne parvenait pas √† contacter le backend.
Sympt√¥me : Les logs de Django affichaient une requests.exceptions.ConnectionError.
Diagnostic : Une analyse rapide a montr√© que les deux serveurs tentaient d'utiliser le port 8000 par d√©faut, cr√©ant une collision qui emp√™chait l'un des deux de d√©marrer correctement.
R√©solution : Le serveur FastAPI a √©t√© explicitement lanc√© sur le port 8001 via la commande uvicorn api.app:app --port 8001. L'URL de base dans la vue Django a √©t√© mise √† jour en cons√©quence.
Le√ßon Apprise : Cet incident m'a appris l'importance de la configuration explicite et de la documentation de la topologie r√©seau, m√™me dans un projet local, pour √©viter les conflits dans une architecture microservices.
Incident 2 : Erreur d'Environnement dans la CI/CD
Contexte : Le premier workflow GitHub Actions √©chouait syst√©matiquement, alors que tous les tests passaient en local.
Sympt√¥me : Les logs du runner GitHub affichaient une erreur ModuleNotFoundError: No module named 'httpx'.
Diagnostic : L'erreur indiquait que l'environnement de la CI ne disposait pas de toutes les d√©pendances n√©cessaires. Le paquet httpx (une d√©pendance de fastapi.testclient) avait √©t√© install√© manuellement en local mais n'avait pas √©t√© ajout√© au fichier requirements.txt.
R√©solution : La d√©pendance manquante a √©t√© ajout√©e au fichier requirements.txt. Apr√®s un nouveau commit, le workflow s'est ex√©cut√© avec succ√®s.
Le√ßon Apprise : Cet incident a √©t√© une d√©monstration pratique de la valeur de l'int√©gration continue. Elle force la discipline dans la gestion des d√©pendances et garantit la reproductibilit√© des environnements, √©vitant ainsi le classique "√ßa marche sur ma machine".

Incident 3 : √âchec du Scraping et Changement de Cible
Contexte : Le script de scraping initial ciblait un site d'actualit√©s qui a mis en place des mesures de s√©curit√© avanc√©es (type Cloudflare) incluant une v√©rification JavaScript, provoquant des √©checs syst√©matiques (erreurs HTTP 403).
Sympt√¥me : Le script de scraping ne retournait aucun article et les logs montraient un code de statut HTTP 403, indiquant un acc√®s refus√©.
Diagnostic : L'analyse de la page cible a r√©v√©l√© qu'elle n√©cessitait l'ex√©cution de JavaScript pour afficher son contenu, une mesure anti-bot courante. S'acharner sur cette cible aurait n√©cessit√© des techniques de contournement complexes et peu fiables.
R√©solution : Une d√©cision strat√©gique a √©t√© prise : changer la source de donn√©es pour `news.bitcoin.com`, un site qui, bien que dynamique, est accessible via un scraping automatis√© avec `undetected-chromedriver`. Le script a √©t√© enti√®rement r√©√©crit pour utiliser ce nouvel outil, piloter un navigateur, attendre le chargement du contenu, et utiliser de nouveaux s√©lecteurs CSS (`div.sc-dDSDPK`) pour extraire les informations.
Le√ßon Apprise : Cet incident a soulign√© l'importance de la flexibilit√© dans la collecte de donn√©es. Plut√¥t que de s'obstiner sur une source probl√©matique, une bonne pratique d'ing√©nierie consiste √† pivoter vers une source de donn√©es alternative plus fiable pour garantir la continuit√© du service.


## 6. Conclusion


Ce projet, "Bitcoin Analyzer", a permis de construire de bout en bout une application full-stack et pilot√©e par l'IA, en respectant les standards professionnels de d√©veloppement logiciel. Allant bien au-del√† d'un simple prototype, le r√©sultat est un service robuste, test√©, document√© et pr√™t √† √™tre d√©ploy√©, qui valide l'ensemble des comp√©tences requises par le titre de D√©veloppeur en Intelligence Artificielle.
6.1 Bilan du Projet et Couverture des Comp√©tences
L'objectif initial, qui √©tait de fournir une information financi√®re centralis√©e et analys√©e, a √©t√© pleinement atteint. L'architecture d√©coupl√©e, s√©parant le backend FastAPI du frontend Django, a prouv√© sa pertinence en permettant un d√©veloppement modulaire et une gestion claire des responsabilit√©s. L'int√©gration d'un service d'IA (Google Gemini), s√©lectionn√© apr√®s une analyse rigoureuse, a permis d'ajouter une valeur m√©tier significative aux donn√©es brutes.
Le projet couvre de mani√®re exhaustive les comp√©tences du r√©f√©rentiel RNCP37827 :
Bloc de Comp√©tences	Comp√©tences Valid√©es	Preuves Concr√®tes dans le Projet
Bloc 1 : La Cha√Æne de la Donn√©e	C1-C5	Scripts de collecte multi-sources (api, web, sql), mod√©lisation de la BDD, et exposition via une API REST document√©e (Swagger UI).
Bloc 2 : Int√©gration de l'IA	C6-C13	Documents de veille et de benchmark, int√©gration de Gemini, tests unitaires avec "mocking", et pipeline de CI/CD avec GitHub Actions.
Bloc 3 : Application & MLOps	C14-C21	Conception de l'application Django, consommation de l'API, packaging avec Docker, surveillance via logging, et r√©solution document√©e d'incidents techniques.
L'approche adopt√©e, ax√©e sur les tests automatis√©s, l'int√©gration continue et la r√©solution m√©thodique d'incidents, d√©montre une ma√Ætrise des pratiques MLOps et DevOps essentielles pour garantir la qualit√© et la maintenabilit√© d'un produit d'IA en conditions r√©elles.
6.2 Perspectives d'√âvolution
Le projet a √©t√© con√ßu pour √™tre une fondation solide. Plusieurs axes d'√©volution sont envisag√©s pour l'avenir, d√©montrant une vision √† long terme du cycle de vie de l'application :
Mont√©e en charge et Performance :
Base de Donn√©es : Migration de SQLite vers un SGBD plus robuste comme PostgreSQL pour g√©rer un plus grand volume de donn√©es et des requ√™tes plus complexes.
Caching : Impl√©mentation d'un syst√®me de cache avec Redis pour les endpoints les plus sollicit√©s de l'API afin de r√©duire la latence et le nombre d'appels √† la base de donn√©es.
S√©curit√© et Fiabilit√© :
Authentification : S√©curisation de l'API avec un syst√®me d'authentification comme OAuth2 pour contr√¥ler l'acc√®s aux endpoints.
D√©ploiement Professionnel : D√©ploiement de l'image Docker de l'API sur un service de conteneurisation cloud (ex: AWS Fargate, Google Cloud Run) et d√©ploiement de l'application Django, le tout int√©gr√© au pipeline de CI/CD pour un d√©ploiement continu.
Fonctionnalit√©s M√©tier :
Analyse Avanc√©e : Entra√Ænement ou fine-tuning d'un mod√®le de langage sp√©cialis√© sur des donn√©es financi√®res pour fournir des analyses encore plus pr√©cises et pr√©dictives.
Interactivit√© : Ajout de graphiques interactifs sur le frontend pour une meilleure visualisation des donn√©es de march√©.
Ce projet ne marque pas une fin, mais le d√©but d'un produit potentiellement viable, dont l'architecture a √©t√© pens√©e d√®s le d√©part pour supporter ces √©volutions futures.