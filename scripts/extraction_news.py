# Fichier : scripts/extraction_news.py
# Version finale utilisant les s√©lecteurs CSS exacts, trouv√©s gr√¢ce au fichier debug_page.html.

import os
import sys
import time
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
import sqlite3


DB_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data", "bitcoin.db")
print(f"CHEMIN DB (SCRIPT): {os.path.abspath(DB_PATH)}") # <---

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from scripts.stockage import init_db

# --- Configuration ---
TARGET_URL = "https://news.bitcoin.com/"
DB_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data", "bitcoin.db")

def extract_news_with_browser():
    """
    Pilote un vrai navigateur et utilise les s√©lecteurs CSS corrects pour extraire les donn√©es.
    """
    print(f"üöÄ D√©marrage du navigateur pour scraper : {TARGET_URL}...")
    articles = []
    
    options = uc.ChromeOptions()
    # options.add_argument('--headless') # √Ä activer pour ne plus voir le navigateur
    driver = uc.Chrome(options=options)
    
    try:
        driver.get(TARGET_URL)
        print("‚è≥ Attente de 5 secondes pour le chargement du contenu par JavaScript...")
        time.sleep(5)

        print("‚úÖ Contenu charg√©. R√©cup√©ration du code HTML final...")
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')

        # --- LE S√âLECTEUR FINAL ET CORRECT ---
        # D'apr√®s debug_page.html, chaque article est dans une div avec la classe "sc-dDSDPK".
        article_containers = soup.select("div.sc-dDSDPK")

        if not article_containers:
            print("‚ùå ERREUR : Aucun article trouv√© avec le s√©lecteur 'div.sc-dDSDPK'.")
            return []
            
        print(f"üì∞ {len(article_containers)} articles potentiels d√©tect√©s.")

        for container in article_containers:
            # √Ä l'int√©rieur de chaque conteneur, le titre est dans un <h6>
            title_tag = container.select_one("h6")
            # Le lien est sur la balise <a> parente
            link_tag = container.find('a', href=True)

            if title_tag and link_tag:
                title = title_tag.get_text(strip=True)
                # Le lien peut √™tre relatif, on le reconstruit
                link = link_tag.get('href')
                if not link.startswith('http'):
                    link = f"https://news.bitcoin.com{link}"

                articles.append({
                    'title': title,
                    'link': link,
                    'content': "Contenu non r√©cup√©r√©." # La description n'est pas sur la page principale
                })
        
        # On ne garde que les articles qui ont un titre (pour filtrer les conteneurs vides)
        articles = [art for art in articles if art.get('title')]
        return articles

    except Exception as e:
        print(f"‚ùå Une erreur est survenue pendant l'automatisation du navigateur : {e}")
        return []
    finally:
        print("üö™ Fermeture du navigateur.")
        driver.quit()

def save_news_to_db(articles):
    """Enregistre les articles dans la base de donn√©es."""
    if not articles: return
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    inserted_count = 0
    for article in articles:
        try:
            cursor.execute("INSERT INTO bitcoin_news (title, link, content) VALUES (?, ?, ?)",
                           (article['title'], article['link'], article['content']))
            inserted_count += 1
        except sqlite3.IntegrityError:
            pass
    conn.commit()
    conn.close()
    if inserted_count > 0: print(f"üíæ {inserted_count} nouveaux articles enregistr√©s.")
    else: print("‚ú® Aucune nouvelle actualit√© √† ajouter.")

def main():
    """Fonction principale."""
    init_db(db_path=DB_PATH)
    articles = extract_news_with_browser()
    if articles:
        print(f"\nüëç {len(articles)} articles ont √©t√© extraits avec succ√®s.")
        save_news_to_db(articles)
    else:
        print("‚ö†Ô∏è L'extraction n'a retourn√© aucun article.")
    print("\n‚úÖ Processus de scraping termin√©.")

if __name__ == "__main__":
    main()